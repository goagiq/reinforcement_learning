# Side-by-Side Config Comparison: Current vs GitHub Repo (Simpler Version)

## Excluded from Comparison
- ‚ùå **Priority 1-3** (Three priorities system)
- ‚ùå **Forecast Features** (Already disabled: `include_forecast_features: false`)

---

## üìä Model Configuration

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **learning_rate** | `0.0003` | `0.0001` | **3x lower** - slower learning |
| **entropy_coef** | `0.01` | `0.025` | **2.5x higher** - more exploration (just fixed from 0.15) |
| **batch_size** | `64` | `128` | **2x larger** |
| **n_steps** | `2048` | `4096` | **2x larger** |
| **n_epochs** | `10` | `30` | **3x larger** |
| **hidden_dims** | `[128, 128, 64]` | `[256, 256, 128]` | **2x larger network** |

---

## üéØ Environment Configuration

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **state_features** | `200-900` (simple) | `900` (base only) | ‚úÖ Similar (no regime/forecast) |
| **action_threshold** | `0.01-0.05` (1-5%) | `0.1` (10%) | **10x higher** - much stricter |
| **max_episode_steps** | `10000` | `10000` | ‚úÖ Same |
| **lookback_bars** | `20` | `20` | ‚úÖ Same |
| **trading_hours** | Simple/None | Complex (3 sessions) | **Much more complex** |

---

## üí∞ Reward Function

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **pnl_weight** | `1.0` | `1.0` | ‚úÖ Same |
| **transaction_cost** | `0.0001` (0.01%) | `0.0002` (0.02%) | **2x higher** |
| **risk_penalty** | `0.1` or None | `0.05` | **Lower** (more permissive) |
| **drawdown_penalty** | `0.1` or None | `0.07` | **Lower** (more permissive) |
| **exploration_bonus** | `None` or `0.00001` | `1.0e-05` (enabled) | ‚úÖ Similar (minimal) |
| **action_diversity_bonus** | `None` | `0.01` | **NEW** - adds complexity |
| **constant_action_penalty** | `None` | `0.05` | **NEW** - adds complexity |
| **loss_mitigation** | `None` or `0.0` | `0.11` (11%) | **NEW** - masks losses |
| **overtrading_penalty** | `None` | `enabled` | **NEW** - adds complexity |
| **optimal_trades_per_episode** | `None` | `1` | **NEW** - very restrictive |
| **profit_factor_required** | `None` | `1.0` | **NEW** - adds constraint |
| **inaction_penalty** | `None` or `0.0001` | `5.0e-05` | ‚úÖ Similar |
| **max_consecutive_losses** | `None` or `3` | `10` | **3x more lenient** |
| **stop_loss_pct** | `0.02` (2%) | `0.015` (1.5%) | **25% tighter** |
| **min_risk_reward_ratio** | `None` or `1.5` | `1.5` | ‚úÖ Same |
| **include_regime_features** | `false` | `false` | ‚úÖ Same (disabled) |

---

## üõ°Ô∏è Quality Filters (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **quality_filters.enabled** | `false` | `true` | **NEW** - adds complexity |
| **min_action_confidence** | `None` | `0.15` | **NEW** - filters trades |
| **min_quality_score** | `None` | `0.4` | **NEW** - filters trades |
| **require_positive_expected_value** | `false` | `false` | ‚úÖ Same (allows exploration) |

---

## üí∏ Transaction Costs & Slippage (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **slippage.enabled** | `false` | `true` | **NEW** - adds complexity |
| **slippage.base_slippage** | `0.0` | `0.00015` | **NEW** - additional cost |
| **slippage.impact_coefficient** | `0.0` | `0.0002` | **NEW** - adds complexity |
| **market_impact.enabled** | `false` | `true` | **NEW** - adds complexity |
| **market_impact.impact_coefficient** | `0.0` | `0.3` | **NEW** - adds complexity |

---

## üéì Training Configuration

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **total_timesteps** | `1000000` | `1000000` | ‚úÖ Same |
| **save_freq** | `10000` | `10000` | ‚úÖ Same |
| **eval_freq** | `5000` | `10000` | **2x less frequent** |
| **use_decision_gate** | `false` | `true` | **NEW** - adds complexity |
| **adaptive_training.enabled** | `false` | `true` | **NEW** - adds complexity |
| **adaptive_training.eval_frequency** | `None` | `5000` | **NEW** - frequent adjustments |
| **transfer_learning** | `false` or simple | `true` (complex) | **Much more complex** |

---

## üö® Risk Management

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **max_position_size** | `1.0` | `1.0` | ‚úÖ Same |
| **max_drawdown** | `0.2` (20%) | `0.2` (20%) | ‚úÖ Same |
| **break_even.enabled** | `false` | `true` | **NEW** - adds complexity |
| **break_even.activation_pct** | `None` | `0.006` | **NEW** - complex logic |
| **break_even.trail_pct** | `None` | `0.0015` | **NEW** - complex logic |
| **break_even.scale_out_fraction** | `None` | `0.5` | **NEW** - complex logic |

---

## üß† Decision Gate (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **decision_gate** | `None` (RL only) | Complex system | **ENTIRELY NEW** |
| **rl_weight** | `1.0` (100%) | `0.6` (60%) | **40% weight reduction** |
| **swarm_weight** | `0.0` | `0.4` (40%) | **NEW** - swarm integration |
| **min_combined_confidence** | `None` | `0.6` | **NEW** - filters trades |
| **min_confluence_required** | `None` | `2` | **NEW** - requires agreement |
| **quality_scorer.enabled** | `false` | `true` | **NEW** - filters trades |
| **position_sizing.enabled** | `false` | `true` | **NEW** - complex sizing |

---

## üîÑ Adaptive Training (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **adaptive_training** | `None` | Entire system | **ENTIRELY NEW** |
| **eval_frequency** | `None` | `5000` | **NEW** - frequent checks |
| **min_trades_per_episode** | `None` | `0.3` | **NEW** - constraint |
| **min_win_rate** | `None` | `0.4` | **NEW** - constraint |
| **auto_save_on_improvement** | `false` | `true` | **NEW** - automatic |

---

## üìà Drift Detection (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **drift_detection.enabled** | `false` | `true` | **NEW** - adds monitoring |
| **baseline_metrics** | `None` | Complex baselines | **NEW** - adds constraints |

---

## ü§ñ Reasoning Engine (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **reasoning.enabled** | `false` | `true` | **NEW** - LLM integration |
| **pre_trade_validation** | `false` | `true` | **NEW** - validates trades |
| **confidence_threshold** | `None` | `0.7` | **NEW** - filters trades |

---

## üêù Agentic Swarm (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **agentic_swarm.enabled** | `false` | `true` | **ENTIRELY NEW** |
| **max_handoffs** | `None` | `10` | **NEW** - complex system |
| **contrarian.enabled** | `false` | `true` | **NEW** - adds logic |
| **elliott_wave.enabled** | `false` | `true` | **NEW** - adds complexity |

---

## üîÑ Continuous Learning (NEW - Not in Simple Repo)

| Setting | GitHub Repo (Simple) | Current (Complex) | Difference |
|---------|---------------------|-------------------|------------|
| **continuous_learning** | `None` | Entire system | **ENTIRELY NEW** |
| **retrain_frequency** | `None` | `1000` | **NEW** - adds complexity |

---

## üìä Summary of Key Differences

### ‚úÖ Settings Similar/Close to Repo
- `state_features`: 900 (base only) - ‚úÖ Simple
- `max_episode_steps`: 10000 - ‚úÖ Same
- `pnl_weight`: 1.0 - ‚úÖ Same
- `include_regime_features`: false - ‚úÖ Disabled
- `include_forecast_features`: false - ‚úÖ Disabled

### ‚ö†Ô∏è Settings More Restrictive Than Repo
- `action_threshold`: **0.1 (10%)** vs 0.01-0.05 (1-5%) - **10x stricter**
- `optimal_trades_per_episode`: **1** vs None - **Very restrictive**
- `stop_loss_pct`: **0.015 (1.5%)** vs 0.02 (2%) - **25% tighter**
- `quality_filters.enabled`: **true** vs false - **Adds filtering**
- `min_action_confidence`: **0.15** vs None - **Filters trades**
- `min_quality_score`: **0.4** vs None - **Filters trades**

### üÜï Entirely New Complex Systems (Not in Simple Repo)
1. **Quality Filters** - Filters trades based on confidence/quality
2. **Slippage Model** - Adds trading costs
3. **Market Impact Model** - Adds trading costs
4. **Decision Gate** - Complex multi-agent system
5. **Adaptive Training** - Automatic parameter adjustment
6. **Drift Detection** - Performance monitoring
7. **Reasoning Engine** - LLM validation
8. **Agentic Swarm** - Multi-agent system
9. **Break-Even Logic** - Complex position management
10. **Continuous Learning** - Auto-retraining

### üìâ Settings More Permissive Than Repo
- `transaction_cost`: 0.0002 vs 0.0001 - **2x higher cost** (more realistic)
- `max_consecutive_losses`: 10 vs 3 - **3x more lenient**
- `loss_mitigation`: 0.11 vs None - **Masks losses** (11% mitigation)

### üéØ Settings That Could Be Simplified
1. **Remove Quality Filters** (or simplify)
2. **Disable Slippage/Market Impact** (simpler cost model)
3. **Disable Decision Gate** (use RL only)
4. **Disable Adaptive Training** (use fixed parameters)
5. **Disable Drift Detection** (simpler monitoring)
6. **Disable Reasoning Engine** (RL only)
7. **Disable Agentic Swarm** (RL only)
8. **Disable Break-Even Logic** (simpler position management)
9. **Reduce action_threshold** (from 0.1 to 0.05)
10. **Reduce optimal_trades_per_episode** (from 1 to None or 5-10)

---

## üí° Recommendations to Match Repo Simplicity

### Priority 1: Reduce Restrictions
```yaml
action_threshold: 0.05  # Reduce from 0.1 to 0.05 (5%)
optimal_trades_per_episode: null  # Remove restriction
stop_loss_pct: 0.02  # Increase from 0.015 to 0.02 (2%)
```

### Priority 2: Simplify Reward Function
```yaml
action_diversity_bonus: 0.0  # Disable
constant_action_penalty: 0.0  # Disable
loss_mitigation: 0.0  # Disable (no loss masking)
overtrading_penalty_enabled: false  # Disable
```

### Priority 3: Disable Complex Systems (For Testing)
```yaml
quality_filters.enabled: false  # Disable quality filters
slippage.enabled: false  # Disable slippage model
market_impact.enabled: false  # Disable market impact
decision_gate: null  # Use RL only (or set use_decision_gate: false)
adaptive_training.enabled: false  # Use fixed parameters
reasoning.enabled: false  # Disable LLM validation
agentic_swarm.enabled: false  # Disable swarm
break_even.enabled: false  # Disable break-even logic
drift_detection.enabled: false  # Disable drift detection
continuous_learning: null  # Disable auto-retraining
```

---

## üîç Most Likely Culprits for Performance Issues

Based on the comparison, these are the **most likely culprits**:

1. **action_threshold: 0.1** (10%) - Too restrictive, blocks many trades
2. **optimal_trades_per_episode: 1** - Extremely restrictive
3. **quality_filters.enabled: true** - Filters many trades
4. **decision_gate complexity** - Multiple filters/validations
5. **loss_mitigation: 0.11** - Masks losses, prevents learning
6. **Multiple new systems** - Each adds complexity and potential issues

